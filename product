import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.compose import ColumnTransformer

# 加载数据
df = pd.read_csv('your_data.csv')
df_last_2000 = df.tail(2000)  # 选取最后2000条数据
df_last_2000['strike time'] = pd.to_datetime(df_last_2000['strike time'])  # 转换日期格式

# 将公司名称列合并为一个字符串
company_cols = ['Company1', 'Company2', 'Company3', 'Company4', 'Company5']  # 替换为您的实际列名
df_last_2000['Companies'] = df_last_2000[company_cols].apply(lambda x: ','.join(x.dropna()), axis=1)

# 按照“strike time”分组
grouped = df_last_2000.groupby(pd.Grouper(key='strike time', freq='W'))

# 定义预处理步骤
numeric_features = ['coupon']
categorical_features = ['Companies']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(), categorical_features)
    ])

# 对每个分组进行处理和相似度计算，并提取最相似的30对组合
most_similar_combinations = {}

for name, group in grouped:
    # 只处理有足够数据的组
    if len(group) < 2:
        continue

    # 应用预处理
    group_features = preprocessor.fit_transform(group)

    # 计算余弦相似度
    similarity_matrix = cosine_similarity(group_features)
    np.fill_diagonal(similarity_matrix, np.nan)

    # 扁平化相似度矩阵并排序
    flattened_similarity_matrix = similarity_matrix.flatten()
    sorted_indices = np.argsort(-flattened_similarity_matrix)

    # 提取前30对最相似的组合索引
    top_30_pairs_indices = sorted_indices[:60]  # 每对两个索引，所以选取前60个索引
    top_30_pairs = [(index // len(group), index % len(group)) for index in top_30_pairs_indices]

    # 存储结果
    most_similar_combinations[name] = [(group.iloc[pair[0]].name, group.iloc[pair[1]].name, flattened_similarity_matrix[index]) for index, pair in zip(top_30_pairs_indices, top_30_pairs)]

# 展示每周最相似的30对组合
for week, pairs in most_similar_combinations.items():
    print(f"Week: {week}")
for pair in pairs:
    print(f"Pair: {pair[0]} and {pair[1]}, Similarity: {pair[2]}")
    print("\n")
